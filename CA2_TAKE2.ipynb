{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8c7b48",
   "metadata": {},
   "source": [
    "Checklist:\n",
    "* make sure there are comments in every cell\n",
    "* make sure all the libraries are just in the top of the notebook\n",
    "* do not repeat code, define functions instead\n",
    "* get mum to read through markdown cells\n",
    "* make sure decision tree and random forest is destinctive labels ie dt_regressor, rf_regressor\n",
    "* always say print(df) not just df\n",
    "* make cool plots\n",
    "* fix the supervised learning model table. Maybe reduce it to 6 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf1d95",
   "metadata": {},
   "source": [
    "**Colours for Visuals** <br>\n",
    "Green = Ireland <br>\n",
    "Blue = France <br>\n",
    "Yellow = Feed <br>\n",
    "Orange = Cattle <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2f501",
   "metadata": {},
   "source": [
    "## Comparing beef prices for carcasses in Ireland and France\n",
    "### A data science approach to investigation into the price of beef carcasses in Ireland and France using data from [European Commission](https://agridata.ec.europa.eu/extensions/DashboardBeef/BeefPricesExt.html#)\n",
    "#### Naomi Tunstead - sba22222\n",
    "#### MSc in Data Analytics\n",
    "#### MSC_DA_CA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e152c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05a3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in libraries needed for analysis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from datetime import timedelta\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb27cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def plot_histogram(df, column_name, title, xlabel):\n",
    "    sns.histplot(data = df, x = column_name, bins = 20, kde = True, color = 'y')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "def shapiro_test(x, color='green'):\n",
    "    p_val = stats.shapiro(x)[1]\n",
    "    status = 'passed'\n",
    "    if p_val < 0.05:\n",
    "        status = 'failed'\n",
    "        color = 'red'\n",
    "    return status, color, p_val\n",
    "\n",
    "def custom_density_plot(df, countries, y_col, main_title, xlabel, ylabel, density_plot_title, box_plot_title):\n",
    "    # Create the subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot the density plots\n",
    "    colors = ['green', 'blue']\n",
    "    for i, country in enumerate(countries):\n",
    "        data = df[df['Member State'] == country][y_col]\n",
    "        sns.kdeplot(data, color=colors[i], label=country, ax=ax[0])\n",
    "    ax[0].set_title(density_plot_title)\n",
    "    \n",
    "    # Plot the box plots\n",
    "    sns.boxplot(x='Member State', y=y_col, data=df, hue='Member State', palette=['green', 'blue'], ax=ax[1])\n",
    "    ax[1].set_title(box_plot_title)\n",
    "    \n",
    "    # Create the Q-Q plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True)\n",
    "    sm.qqplot(df[df['Member State'] == 'Ireland'][y_col], ax=ax[0], line='s', color='green')\n",
    "    ax[0].set_title('Q-Q Plot of {} in Ireland'.format(ylabel))\n",
    "    ax[0].set_xlabel('Theoretical Quantiles')\n",
    "    ax[0].set_ylabel('Sample Quantiles')\n",
    "    sm.qqplot(df[df['Member State'] == 'France'][y_col], ax=ax[1], line='s', color='blue')\n",
    "    ax[1].set_title('Q-Q Plot of {} in France'.format(ylabel))\n",
    "    ax[1].set_xlabel('Theoretical Quantiles')\n",
    "    ax[1].set_ylabel('Sample Quantiles')\n",
    "    \n",
    "    # Set the main title of the figure\n",
    "    fig.suptitle(main_title)\n",
    "    \n",
    "    # Perform the Shapiro-Wilk test on the data\n",
    "    status, color, p_val = shapiro_test(df[y_col])\n",
    "    \n",
    "    # Set the title of the Q-Q plot figure to include the result of the normality test\n",
    "    fig.suptitle('{} (p_value = {})'.format(status, p_val), color=color, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1cb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the xlsx files\n",
    "df_cattle = pd.read_excel('ireland_france_2_years_beef.xlsx')\n",
    "df_feed = pd.read_excel('barley_prices.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be571b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  Week Begin Date   End Date Member State      Category Product  \\\n",
      "0     2022    50 2022-12-12 2022-12-18      Ireland  Young cattle    Z O3   \n",
      "1     2022    50 2022-12-12 2022-12-18      Ireland  Young cattle    Z O2   \n",
      "2     2022    50 2022-12-12 2022-12-18      Ireland  Young cattle    Z U3   \n",
      "3     2022    50 2022-12-12 2022-12-18      Ireland  Young cattle    Z R3   \n",
      "4     2022    50 2022-12-12 2022-12-18      Ireland  Young cattle    Z R2   \n",
      "...    ...   ...        ...        ...          ...           ...     ...   \n",
      "6145  2021     3 2021-01-18 2021-01-24       France         Bulls    B R3   \n",
      "6146  2021     2 2021-01-11 2021-01-17      Ireland         Bulls    B R3   \n",
      "6147  2021     2 2021-01-11 2021-01-17       France         Bulls    B R3   \n",
      "6148  2021     1 2021-01-04 2021-01-10      Ireland         Bulls    B R3   \n",
      "6149  2021     1 2021-01-04 2021-01-10       France         Bulls    B R3   \n",
      "\n",
      "       Price  \n",
      "0     406.10  \n",
      "1     416.31  \n",
      "2     491.00  \n",
      "3     497.31  \n",
      "4     510.00  \n",
      "...      ...  \n",
      "6145  302.00  \n",
      "6146  272.63  \n",
      "6147  301.00  \n",
      "6148  282.74  \n",
      "6149  305.00  \n",
      "\n",
      "[6150 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the cattle DataFrame\n",
    "print(df_cattle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35945f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Marketing Year Reference period Member State Product Name  \\\n",
      "0        2022/2023       2022-07-14       France  Feed barley   \n",
      "1        2022/2023       2022-07-14      Ireland  Feed barley   \n",
      "2        2022/2023       2022-07-21       France  Feed barley   \n",
      "3        2022/2023       2022-07-21      Ireland  Feed barley   \n",
      "4        2022/2023       2022-07-28       France  Feed barley   \n",
      "..             ...              ...          ...          ...   \n",
      "236      2020/2021       2021-06-17      Ireland  Feed barley   \n",
      "237      2020/2021       2021-06-24       France  Feed barley   \n",
      "238      2020/2021       2021-06-24      Ireland  Feed barley   \n",
      "239      2020/2021       2021-07-01       France  Feed barley   \n",
      "240      2020/2021       2021-07-01      Ireland  Feed barley   \n",
      "\n",
      "                    Market Name  \\\n",
      "0                         Rouen   \n",
      "1    Dublin/North East/Midlands   \n",
      "2                         Rouen   \n",
      "3    Dublin/North East/Midlands   \n",
      "4                         Rouen   \n",
      "..                          ...   \n",
      "236  Dublin/North East/Midlands   \n",
      "237                       Rouen   \n",
      "238  Dublin/North East/Midlands   \n",
      "239                       Rouen   \n",
      "240  Dublin/North East/Midlands   \n",
      "\n",
      "                                            Stage Name  Price (â‚¬/Tonne)  \n",
      "0    Delivered to port - grain delivered to a port ...           300.25  \n",
      "1    Deliver to first customer - silo or processing...           380.00  \n",
      "2    Delivered to port - grain delivered to a port ...           300.25  \n",
      "3    Deliver to first customer - silo or processing...           325.00  \n",
      "4    Delivered to port - grain delivered to a port ...           292.50  \n",
      "..                                                 ...              ...  \n",
      "236  Deliver to first customer - silo or processing...           238.00  \n",
      "237  Delivered to port - grain delivered to a port ...           217.50  \n",
      "238  Deliver to first customer - silo or processing...           240.00  \n",
      "239  Delivered to port - grain delivered to a port ...           204.50  \n",
      "240  Deliver to first customer - silo or processing...           240.00  \n",
      "\n",
      "[241 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the feed DataFrame\n",
    "print(df_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63fd21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  Week Begin Date Member State      Category   Price\n",
      "0     2022    50 2022-12-12      Ireland  Young cattle  406.10\n",
      "1     2022    50 2022-12-12      Ireland  Young cattle  416.31\n",
      "2     2022    50 2022-12-12      Ireland  Young cattle  491.00\n",
      "3     2022    50 2022-12-12      Ireland  Young cattle  497.31\n",
      "4     2022    50 2022-12-12      Ireland  Young cattle  510.00\n",
      "...    ...   ...        ...          ...           ...     ...\n",
      "6145  2021     3 2021-01-18       France         Bulls  302.00\n",
      "6146  2021     2 2021-01-11      Ireland         Bulls  272.63\n",
      "6147  2021     2 2021-01-11       France         Bulls  301.00\n",
      "6148  2021     1 2021-01-04      Ireland         Bulls  282.74\n",
      "6149  2021     1 2021-01-04       France         Bulls  305.00\n",
      "\n",
      "[6150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'End Date' and 'Week' column because its is not useful \n",
    "df_cattle = df_cattle.drop(columns=['End Date', 'Product'])\n",
    "\n",
    "# Check result\n",
    "print(df_cattle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81832c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year    Week   Price\n",
      "count 6150.00 6150.00 6150.00\n",
      "mean  2021.48   25.69  423.03\n",
      "std      0.50   14.71   70.99\n",
      "min   2021.00    1.00  182.00\n",
      "25%   2021.00   13.00  375.02\n",
      "50%   2021.00   25.00  420.93\n",
      "75%   2022.00   38.00  473.93\n",
      "max   2022.00   52.00  731.00\n"
     ]
    }
   ],
   "source": [
    "# Use df_cattle.describe() to get summary statistics of the data\n",
    "# This can help us understand the distribution and overall characteristics of the data\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Check result\n",
    "print(df_cattle.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8489c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Price (â‚¬/Tonne)\n",
      "count           241.00\n",
      "mean            260.91\n",
      "std              69.64\n",
      "min             161.50\n",
      "25%             205.00\n",
      "50%             240.00\n",
      "75%             308.00\n",
      "max             420.00\n"
     ]
    }
   ],
   "source": [
    "# Generate descriptive statistics of the data\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Check result\n",
    "print(df_feed.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328aaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Begin Date' column to 'Reference period' so that we can used this column to merge the feed DataFrame\n",
    "df_cattle = df_cattle.rename(columns={'Begin Date': 'Reference period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539f1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reference period Member State  Price (â‚¬/Tonne)\n",
      "0         2022-07-14       France           300.25\n",
      "1         2022-07-14      Ireland           380.00\n",
      "2         2022-07-21       France           300.25\n",
      "3         2022-07-21      Ireland           325.00\n",
      "4         2022-07-28       France           292.50\n",
      "..               ...          ...              ...\n",
      "236       2021-06-17      Ireland           238.00\n",
      "237       2021-06-24       France           217.50\n",
      "238       2021-06-24      Ireland           240.00\n",
      "239       2021-07-01       France           204.50\n",
      "240       2021-07-01      Ireland           240.00\n",
      "\n",
      "[241 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Market Name', 'Stage Name' and 'Marketing Year' columns as they are not of interest\n",
    "df_feed = df_feed.drop(columns=['Market Name', 'Stage Name', 'Marketing Year', 'Product Name'])\n",
    "\n",
    "# Check result\n",
    "print(df_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a3b390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6150 entries, 0 to 6149\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Year              6150 non-null   int64         \n",
      " 1   Week              6150 non-null   int64         \n",
      " 2   Reference period  6150 non-null   datetime64[ns]\n",
      " 3   Member State      6150 non-null   object        \n",
      " 4   Category          6150 non-null   object        \n",
      " 5   Price             6150 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(2)\n",
      "memory usage: 288.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatypes for each column and determine if they are correct or not\n",
    "df_cattle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5cd618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Reference period  241 non-null    datetime64[ns]\n",
      " 1   Member State      241 non-null    object        \n",
      " 2   Price (â‚¬/Tonne)   241 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the datatypes for each column and determine if they are correct or not\n",
    "df_feed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b730fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reference period Member State  Price (â‚¬/Tonne)\n",
      "0         2022-07-11       France           300.25\n",
      "1         2022-07-11      Ireland           380.00\n",
      "2         2022-07-18       France           300.25\n",
      "3         2022-07-18      Ireland           325.00\n",
      "4         2022-07-25       France           292.50\n",
      "..               ...          ...              ...\n",
      "236       2021-06-14      Ireland           238.00\n",
      "237       2021-06-21       France           217.50\n",
      "238       2021-06-21      Ireland           240.00\n",
      "239       2021-06-28       France           204.50\n",
      "240       2021-06-28      Ireland           240.00\n",
      "\n",
      "[241 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Change all the Reference periods for df_feed to be 3 days previously to align them with the Reference period in df_cattle\n",
    "df_feed[\"Reference period\"] = df_feed[\"Reference period\"].apply(lambda x: x - timedelta(days=3))\n",
    "\n",
    "# Check result\n",
    "print(df_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "349de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the \"Age\" column in descending order\n",
    "df_feed = df_feed.sort_values(by='Reference period', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d231482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of rows and columns to be displayed to 1000 in order to show the whole DataFrame to check results\n",
    "# pd.options.display.max_rows = 1000\n",
    "# pd.options.display.max_columns = 1000\n",
    "\n",
    "# Check results\n",
    "# df_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5778ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  Week Reference period Member State      Category  Price  \\\n",
      "0     2022    50       2022-12-12      Ireland  Young cattle 406.10   \n",
      "1     2022    50       2022-12-12      Ireland  Young cattle 416.31   \n",
      "2     2022    50       2022-12-12      Ireland  Young cattle 491.00   \n",
      "3     2022    50       2022-12-12      Ireland  Young cattle 497.31   \n",
      "4     2022    50       2022-12-12      Ireland  Young cattle 510.00   \n",
      "...    ...   ...              ...          ...           ...    ...   \n",
      "6145  2021     3       2021-01-18       France         Bulls 302.00   \n",
      "6146  2021     2       2021-01-11      Ireland         Bulls 272.63   \n",
      "6147  2021     2       2021-01-11       France         Bulls 301.00   \n",
      "6148  2021     1       2021-01-04      Ireland         Bulls 282.74   \n",
      "6149  2021     1       2021-01-04       France         Bulls 305.00   \n",
      "\n",
      "      Price (â‚¬/Tonne)  \n",
      "0              298.00  \n",
      "1              298.00  \n",
      "2              298.00  \n",
      "3              298.00  \n",
      "4              298.00  \n",
      "...               ...  \n",
      "6145           216.08  \n",
      "6146           197.00  \n",
      "6147           204.08  \n",
      "6148           196.00  \n",
      "6149              NaN  \n",
      "\n",
      "[6150 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform a left join on the two DataFrames\n",
    "df = df_cattle.merge(df_feed, on=['Reference period', 'Member State'], how='left')\n",
    "\n",
    "# Check result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d0a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns 'Price' and 'Price (â‚¬/Tonne)' to 'Cattle Price' and 'Feed Price (â‚¬/Tonne)' so there is no confusion\n",
    "df = df.rename(columns={'Price': 'Cattle Price', 'Price (â‚¬/Tonne)': 'Feed Price (â‚¬/Tonne)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83425a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                      0\n",
       "Week                      0\n",
       "Reference period          0\n",
       "Member State              0\n",
       "Category                  0\n",
       "Cattle Price              0\n",
       "Feed Price (â‚¬/Tonne)    317\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7a6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Reference period' as it has a data type of datetime64[ns] which may cause problem with our model later\n",
    "df = df.drop(columns=['Reference period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "313399b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap 'Price' column to be target variable\n",
    "df = df[['Year', 'Week', 'Member State', 'Feed Price (â‚¬/Tonne)', 'Category', 'Cattle Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4d1f62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of 'Price (â‚¬/Tonne)' before imputation of missing values\n",
    "plot_histogram(df, 'Feed Price (â‚¬/Tonne)', 'Distribution of Feed Price', 'Feed Price (â‚¬/Tonne)')\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img1_before_imputation_histogram.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8239f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Member State</th>\n",
       "      <th>Feed Price (â‚¬/Tonne)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cattle Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>298.00</td>\n",
       "      <td>Young cattle</td>\n",
       "      <td>406.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>298.00</td>\n",
       "      <td>Young cattle</td>\n",
       "      <td>416.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>298.00</td>\n",
       "      <td>Young cattle</td>\n",
       "      <td>491.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>298.00</td>\n",
       "      <td>Young cattle</td>\n",
       "      <td>497.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>50</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>298.00</td>\n",
       "      <td>Young cattle</td>\n",
       "      <td>510.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>France</td>\n",
       "      <td>216.08</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>302.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>197.00</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>272.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>France</td>\n",
       "      <td>204.08</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>301.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>196.00</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>282.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>305.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Week Member State  Feed Price (â‚¬/Tonne)      Category  \\\n",
       "0     2022    50      Ireland                298.00  Young cattle   \n",
       "1     2022    50      Ireland                298.00  Young cattle   \n",
       "2     2022    50      Ireland                298.00  Young cattle   \n",
       "3     2022    50      Ireland                298.00  Young cattle   \n",
       "4     2022    50      Ireland                298.00  Young cattle   \n",
       "...    ...   ...          ...                   ...           ...   \n",
       "6145  2021     3       France                216.08         Bulls   \n",
       "6146  2021     2      Ireland                197.00         Bulls   \n",
       "6147  2021     2       France                204.08         Bulls   \n",
       "6148  2021     1      Ireland                196.00         Bulls   \n",
       "6149  2021     1       France                   NaN         Bulls   \n",
       "\n",
       "      Cattle Price  \n",
       "0           406.10  \n",
       "1           416.31  \n",
       "2           491.00  \n",
       "3           497.31  \n",
       "4           510.00  \n",
       "...            ...  \n",
       "6145        302.00  \n",
       "6146        272.63  \n",
       "6147        301.00  \n",
       "6148        282.74  \n",
       "6149        305.00  \n",
       "\n",
       "[6150 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59ebfcb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'interactive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpanel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpn\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteractive\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get a list of unique member states\u001b[39;00m\n\u001b[0;32m      6\u001b[0m member_states \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMember State\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'interactive'"
     ]
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "df = (df).interactive\n",
    "\n",
    "# Get a list of unique member states\n",
    "member_states = df['Member State'].unique().tolist()\n",
    "# Get a list of unique categories\n",
    "categories = df['Category'].unique().tolist()\n",
    "\n",
    "# Define a MultiSelect widget for the Category filter\n",
    "category_select = pn.widgets.MultiSelect(name='Category', options=categories)\n",
    "# Define a slider widget for the Year and Week filter\n",
    "year_slider = pn.widgets.IntSlider(name='Year', start=2021, end=2022, step=1)\n",
    "week_slider = pn.widgets.IntSlider(name='Week', start=1, end=52, step=1)\n",
    "# Define a Select widget for the Member State filter\n",
    "member_state_select = pn.widgets.Select(name='Member State', options=member_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from holoviews import opts\n",
    "from holoviews import streams\n",
    "\n",
    "# Define the column to use for the x-axis\n",
    "x_col = 'Feed Price (â‚¬/Tonne)'\n",
    "\n",
    "# Define the plot title\n",
    "title = 'Feed Price Distribution'\n",
    "\n",
    "# Create a stream that updates the plot data whenever a filter value changes\n",
    "filter_stream = streams.Stream.define(\n",
    "    'Filter',\n",
    "    Year=year_slider,\n",
    "    Week=week_slider,\n",
    "    Member_State=member_state_select,\n",
    "    Category=category_select,\n",
    ")\n",
    "\n",
    "# Create a histogram of the feed price data\n",
    "feed_price_hist = df[x_col].hvplot.hist(y='Feed Price (â‚¬/Tonne)', title=title).opts(show_grid=True)\n",
    "\n",
    "# Define a function that updates the plot data based on the selected filters\n",
    "def update_plot(new_values):\n",
    "    Year = new_values['Year']\n",
    "    Week = new_values['Week']\n",
    "    Member_State = new_values['Member_State']\n",
    "    Category = new_values['Category']\n",
    "    \n",
    "    plot_data = df[(df['Year'].isin([Year])) & \n",
    "                   (df['Week'].isin([Week])) & \n",
    "                   (df['Member State'].isin([Member_State])) & \n",
    "                   (df['Category'].isin([Category]))]\n",
    "    return plot_data[x_col].hvplot.hist(y='Feed Price (â‚¬/Tonne)', title=title).opts(show_grid=True)\n",
    "\n",
    "\n",
    "# Add a callback that updates the plot data whenever a filter value changes\n",
    "#filter_stream.add_subscriber(update_plot)\n",
    "\n",
    "\n",
    "\n",
    "# Display the histogram\n",
    "feed_price_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "# Define a MultiSelect widget for the Category filter\n",
    "category_select = pn.widgets.MultiSelect(name='Category', options=categories)\n",
    "\n",
    "# Define a slider widget for the Year and Week filter\n",
    "year_slider = pn.widgets.IntSlider(name='Year', start=2021, end=2022, step=1)\n",
    "week_slider = pn.widgets.IntSlider(name='Week', start=1, end=52, step=1)\n",
    "# Define a Select widget for the Member State filter\n",
    "member_state_select = pn.widgets.Select(name='Member State', options=member_states)\n",
    "\n",
    "# Define a Select widget for the column name\n",
    "column_name_select = pn.widgets.Select(name='Column Name', options=list(df.columns))\n",
    "\n",
    "def plot_histogram(df, column_name, title):\n",
    "    sns.histplot(data = df, x = column_name, bins = 20, kde = True, color = 'y')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "pn.interact(plot_histogram, df=df, column_name=column_name_select, title='Distribution of Feed Price')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f590a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "# Create the plot\n",
    "plot_histogram(df, 'Feed Price (â‚¬/Tonne)', 'Distribution of Feed Price', 'Feed Price (â‚¬/Tonne)')\n",
    "\n",
    "# Add a slider to the plot\n",
    "ax_slider = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "slider = Slider(ax_slider, 'Feed Price (â‚¬/Tonne)', df['Feed Price (â‚¬/Tonne)'].min(), df['Feed Price (â‚¬/Tonne)'].max(), valinit=df['Feed Price (â‚¬/Tonne)'].max())\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    x_range = slider.val\n",
    "    plt.xlim(0, x_range)\n",
    "    plt.draw()\n",
    "\n",
    "slider.on_changed(update)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.models import ColumnDataSource, RangeSlider\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "def plot_histogram(df, x_col, title, x_label, week=None, year=None):\n",
    "    # Select data for the given week and year\n",
    "    if week is not None:\n",
    "        df = df[df['Week'] == week]\n",
    "    if year is not None:\n",
    "        df = df[df['Year'] == year]\n",
    "    \n",
    "    # Create the histogram\n",
    "    plt.hist(df[x_col], bins=20)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('Number of Observations')\n",
    "\n",
    "# Create the plot\n",
    "plot_histogram(df, 'Feed Price (â‚¬/Tonne)', 'Distribution of Feed Price', 'Feed Price (â‚¬/Tonne)')\n",
    "\n",
    "# Add a slider for the week\n",
    "ax_slider_week = plt.axes([0.9, 0.1, 0.03, 0.65])\n",
    "slider_week = Slider(ax_slider_week, 'Week', df['Week'].min(), df['Week'].max(), valinit=df['Week'].max(), valstep=1, orientation='vertical')\n",
    "\n",
    "# Add a slider for the year\n",
    "ax_slider_year = plt.axes([0.95, 0.1, 0.03, 0.65])\n",
    "slider_year = Slider(ax_slider_year, 'Year', df['Year'].min(), df['Year'].max(), valinit=df['Year'].max(), valstep=1, orientation='vertical')\n",
    "\n",
    "def update(val):\n",
    "    week = int(slider_week.val)\n",
    "    year = int(slider_year.val)\n",
    "    plot_histogram(df, 'Feed Price (â‚¬/Tonne)', 'Distribution of Feed Price', 'Feed Price (â‚¬/Tonne)', week=week, year=year)\n",
    "    plt.draw()\n",
    "\n",
    "slider_week.on_changed(update)\n",
    "slider_year.on_changed(update)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill the missing values in the \"Price (â‚¬/Tonne)\" column\n",
    "df[\"Feed Price (â‚¬/Tonne)\"].ffill(inplace=True)\n",
    "\n",
    "# Check result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isnull().any().any():\n",
    "    print(\"There are nan values in the dataframe.\")\n",
    "else:\n",
    "    print(\"There are no nan values in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84448c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isin([np.inf, -np.inf]).any().any():\n",
    "    print(\"There are inf values in the dataframe.\")\n",
    "else:\n",
    "    print(\"There are no inf values in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfd15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of 'Price (â‚¬/Tonne)' to check for any change to distribution after imputation of missing values\n",
    "plot_histogram(df, 'Feed Price (â‚¬/Tonne)', 'Distribution of Feed Price', 'Feed Price (â‚¬/Tonne)')\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img2_after_imputation_histogram.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66516577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd57c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot of price distribution of cattle by country\n",
    "plt.title('Distribution of Cattle Price')\n",
    "sns.swarmplot(data = df, x=df['Member State'], y=df['Cattle Price'], hue = 'Category')\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0);\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img3_violin_plot.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Dropdown\n",
    "\n",
    "# Create the plot\n",
    "plt.title('Distribution of Cattle Price')\n",
    "sns.swarmplot(data = df, x=df['Member State'], y=df['Cattle Price'], hue = 'Category')\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "# Add a slider to the plot\n",
    "ax_slider = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "slider = Slider(ax_slider, 'Year', df['Year'].min(), df['Year'].max(), valinit=df['Year'].min())\n",
    "\n",
    "# Add a dropdown menu to the plot\n",
    "ax_dropdown = plt.axes([0.25, 0.15, 0.65, 0.03])\n",
    "dropdown = Dropdown(ax_dropdown, 'Category', df['Category'].unique())\n",
    "\n",
    "def update(val):\n",
    "    year = int(slider.val)\n",
    "    category = dropdown.value\n",
    "    df_year_category = df[(df['Year'] == year) & (df['Category'] == category)]\n",
    "    sns.swarmplot(data = df_year_category, x=df_year_category['Member State'], y=df_year_category['Cattle Price'], hue = 'Category')\n",
    "    plt.draw()\n",
    "\n",
    "slider.on_changed(update)\n",
    "dropdown.on_changed(update)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, CategoricalColorMapper, Slider\n",
    "from bokeh.layouts import column\n",
    "\n",
    "# Create a ColumnDataSource from the dataframe\n",
    "source = ColumnDataSource(df)\n",
    "\n",
    "# Map the 'Category' column to colors\n",
    "color_mapper = CategoricalColorMapper(factors=df['Category'].unique(), palette=['red', 'green', 'blue'])\n",
    "\n",
    "# Create the plot\n",
    "p = figure(title='Distribution of Cattle Price', x_range=df['Member State'].unique())\n",
    "p.circle(x='Member State', y='Cattle Price', source=source, color={'field': 'Category', 'transform': color_mapper})\n",
    "\n",
    "# Add a slider to the plot\n",
    "slider = Slider(start=df['Year'].min(), end=df['Year'].max(), value=df['Year'].min(), step=1, title='Year')\n",
    "\n",
    "# Update the plot based on the slider value\n",
    "def update_plot(attr, old, new):\n",
    "    year = slider.value\n",
    "    df_year = df[df['Year'] == year]\n",
    "    source.data = ColumnDataSource(df_year).data\n",
    "\n",
    "slider.on_change('value', update_plot)\n",
    "\n",
    "# Show the plot\n",
    "show(column(p, slider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Pearson correlation between all pairs of columns\n",
    "c_df = df.corr(method='pearson')\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "# Use the seaborn heatmap function to create a heatmap of the correlations\n",
    "sns.heatmap(c_df, cmap='YlOrBr', annot=True)\n",
    "\n",
    "# Set the plot title and labels\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Columns')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img4_pearson_corr_heatmap.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c78ba",
   "metadata": {},
   "source": [
    "The custom_barplot function is a custom function for visualizing the distribution of a column in a Pandas DataFrame. The function takes a DataFrame (df1) and a column name (col1) as input and creates a figure with four subplots: a histogram, a density plot, a Q-Q plot, and a box plot of the column.\n",
    "\n",
    "The first two lines of the function check the size of the column and, if it has more than 5000 values, select a random sample of 5000 values from the column. This is done to avoid warnings about the size of the data being used with the Shapiro-Wilk test, which is unreliable with sample sizes larger than 5000, and for performance reasons.\n",
    "\n",
    "The function then creates a figure and a 2x2 grid of subplots using plt.subplots. The histogram and density plot of the column are plotted using the plot method of the Pandas Series with the kind parameter set to 'hist' and 'kde', respectively. The Q-Q plot is created using the probplot function from the scipy.stats module. The box plot of the column is plotted using the plot method of the Pandas Series with the kind parameter set to 'box'.\n",
    "\n",
    "Finally, the function calls the shapiro_test function to perform a Shapiro-Wilk test of normality on the column and returns the result as a tuple containing the status of the test (either 'Normal' or 'Not normal'), the color to use for the plot title, and the p-value of the test. The function then adds a plot title to the figure with the result of the normality test and the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09284c",
   "metadata": {},
   "source": [
    "There are a few ways you can improve the code:\n",
    "\n",
    "Make the custom_barplot function more flexible by allowing it to accept multiple columns and countries, and to customize the title and labels of the plots. This way, you can use the function to create plots for different combinations of columns and countries without having to modify the function itself.\n",
    "\n",
    "Use more descriptive and meaningful variable names. This can make the code easier to understand and maintain.\n",
    "\n",
    "Use the seaborn library to create the plots. This library provides a variety of high-level plotting functions that can make your plots more visually appealing and easier to create.\n",
    "\n",
    "Consider using the pandas plot method to create the plots. This method provides a convenient way to create various types of plots using the DataFrame and Series objects.\n",
    "\n",
    "Use the matplotlib subplots function to create the plots. This function allows you to specify the number of rows and columns of subplots, and returns a tuple of the Figure and Axes objects. This can be more convenient than creating the plots manually.\n",
    "\n",
    "Use matplotlib tight_layout function to adjust the layout of the plots. This can help avoid overlapping plots and text, and make the plots more visually appealing.\n",
    "\n",
    "Consider using the scipy anderson_ksamp function to test for normality instead of the shapiro function. The anderson_ksamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b03cd",
   "metadata": {},
   "source": [
    "### Generate a Q-Q plot to compare the distribution of data to a theoretical distribution (e.g. normal)\n",
    "### The plot shows the quantiles of the data against the quantiles of the theoretical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad907d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate density plots, box plots and Q-Q plot for cattle prices in France and Ireland\n",
    "# The density plots show the distribution of the data, the box plots provide summary statistics and use a Q-Q plot \n",
    "# to assess the normality of the data. If the data is normally distributed, the points on the plot should lie close\n",
    "# to a straight line\n",
    "density_plot_title = 'Cattle Price Density Plot'\n",
    "box_plot_title = 'Cattle Price Box Plot'\n",
    "custom_density_plot(df, ['France', 'Ireland'], \n",
    "                    'Cattle Price', \n",
    "                    'Q-Q Plots of Cattle Prices in Ireland and France', \n",
    "                    'Country', \n",
    "                    'Cattle Price',\n",
    "                    density_plot_title, \n",
    "                    box_plot_title)\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img4_pearson_corr_cattle_price.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfad726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate density plots, box plots and Q-Q plot for feed prices in France and Ireland\n",
    "density_plot_title = 'Feed Price Density Plot'\n",
    "box_plot_title = 'Feed Price Box Plot'\n",
    "custom_density_plot(df, ['France', 'Ireland'], \n",
    "                    'Feed Price (â‚¬/Tonne)', \n",
    "                    'Q-Q Plots of Feed Prices in Ireland and France', \n",
    "                    'Country', \n",
    "                    'Feed Price',\n",
    "                    density_plot_title, \n",
    "                    box_plot_title)\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img5_pearson_corr_feed_price.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfecd12",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538693c",
   "metadata": {},
   "source": [
    "## Levene's test\n",
    "\n",
    "To check if the variances of two samples are equal, you can use the Levene's test, which is a statistical test that compares the variances of two or more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d444e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0 = varience are equal\n",
    "#H1 = variance are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for t-test\n",
    "ireland_beef = df[df['Member State'] == 'Ireland']['Cattle Price']\n",
    "france_beef = df[df['Member State'] == 'France']['Cattle Price']\n",
    "\n",
    "# Perform Levene's test\n",
    "statistic, p_value = stats.levene(ireland_beef, france_beef)\n",
    "\n",
    "print(\"statistic: \", statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac999c",
   "metadata": {},
   "source": [
    "If the p-value is less than the predetermined threshold, 0.05, you can conclude that the variances of the two samples are not equal. In that case, you may need to use a different statistical test that does not assume equal variances, such as the Welch's t-test or the Brown-Forsythe test. However our p-value is 2.48 which is greater than 0.05. Therefore, it means that the observed results are not statistically significant and it is not possible to reject the null hypothesis. This does not necessarily mean that the null hypothesis is true, but rather that the observed data do not provide sufficient evidence to reject the null hypothesis.\n",
    "\n",
    "*It's important to note that the Levene's test assumes that the data are normally distributed. If this assumption is not met, you may need to use a different test to compare the variances of the two samples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a52a94",
   "metadata": {},
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0 = means are equal\n",
    "#H1 = means are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test\n",
    "t_statistic, p_value = stats.ttest_ind(ireland_beef, france_beef)\n",
    "\n",
    "print(\"t-statistic: \", t_statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eae41d",
   "metadata": {},
   "source": [
    "## Non Parametric Test - Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66edf50",
   "metadata": {},
   "source": [
    "#### H0 = no difference between the samples\n",
    "#### H1 = there is a difference between the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ireland_feed = df[df['Member State'] == 'Ireland']['Feed Price (â‚¬/Tonne)']\n",
    "france_feed = df[df['Member State'] == 'France']['Feed Price (â‚¬/Tonne)']\n",
    "\n",
    "statistic, p_value = mannwhitneyu(ireland_feed, france_feed)\n",
    "\n",
    "print(\"U-statistic: \", statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176aecaf",
   "metadata": {},
   "source": [
    "The U-statistic is a measure of the difference between the two samples, and the p-value is used to determine the statistical significance of the difference. If the p-value is less than 0.05, it can be concluded that there is a significant difference between the two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776646c3",
   "metadata": {},
   "source": [
    "The U-statistic is a measure of the difference between two samples in a Mann-Whitney U test. It is calculated as the sum of the ranks of the sample with the smaller size in the combined sample.\n",
    "\n",
    "In the Mann-Whitney U test, the null hypothesis is that there is no difference between the two samples. The alternative hypothesis is that there is a difference between the samples. The U-statistic is used to determine the statistical significance of the difference between the samples.\n",
    "\n",
    "If the U-statistic is small, it suggests that there is a significant difference between the samples. This is because a small U-statistic indicates that the ranks of the smaller sample are concentrated at the extremes of the combined sample, which suggests that the distributions of the two samples are different. On the other hand, if the U-statistic is large, it suggests that there is not a significant difference between the samples.\n",
    "\n",
    "The U-statistic can be used in conjunction with the p-value to make a decision about the null hypothesis. If the p-value is less than 0.05, it can be concluded that there is a significant difference between the samples, and the null hypothesis can be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fdbf0",
   "metadata": {},
   "source": [
    "## Non Parametric Test - Wilcoxon Signed-rank test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f971d",
   "metadata": {},
   "source": [
    "not going to work because the samples are independent of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import wilcoxon\n",
    "\n",
    "# statistic, p_value = wilcoxon(ireland_feed, france_feed)\n",
    "\n",
    "# print(\"Wilcoxon statistic: \", statistic)\n",
    "# print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ireland_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50789211",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(france_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951333a",
   "metadata": {},
   "source": [
    "The Wilcoxon statistic is a measure of the difference between the two samples, and the p-value is used to determine the statistical significance of the difference. If the p-value is less than 0.05, it can be concluded that there is a significant difference between the two samples.\n",
    "\n",
    "It's important to note that the Wilcoxon signed-rank test is used when the samples are related, meaning that the observations in one sample are paired with observations in the other sample. This test is not appropriate for independent samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0411dfb",
   "metadata": {},
   "source": [
    "## Non Parametric Test - Chi-Square Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2df896",
   "metadata": {},
   "source": [
    "The hypothesis test for a chi-square test is used to determine if there is a significant association between two categorical variables. The null hypothesis is that there is no association between the two variables, and the alternative hypothesis is that there is an association between the variables.\n",
    "\n",
    "To perform the test, a contingency table is created to summarize the counts of each combination of the two variables. The chi-square test is then applied to the contingency table to determine the statistical significance of the association between the variables.\n",
    "\n",
    "If the p-value obtained from the chi-square test is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant association between the two variables, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant association between the variables, and the null hypothesis is accepted.\n",
    "\n",
    "It's important to note that the chi-square test is used to determine if there is a significant association between two categorical variables. It is not appropriate for continuous or ordinal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contingency table\n",
    "table = pd.crosstab(df['Feed Price (â‚¬/Tonne)'], df['Cattle Price'])\n",
    "\n",
    "statistic, p_value, degrees_of_freedom, expected = chi2_contingency(table)\n",
    "\n",
    "print(\"Chi-square statistic: \", statistic)\n",
    "print(\"p-value: \", p_value)\n",
    "print(\"degrees of freedom: \", degrees_of_freedom)\n",
    "print(\"expected frequencies: \", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169ccd0",
   "metadata": {},
   "source": [
    "The chi-square statistic is a measure of the difference between the observed and expected frequencies in the contingency table. It is calculated as the sum of the squared differences between the observed and expected frequencies, divided by the expected frequencies. The larger the chi-square statistic, the stronger the evidence against the null hypothesis (i.e., the more evidence there is for a significant association between the variables).\n",
    "\n",
    "The p-value is used to determine the statistical significance of the association between the variables. It is the probability of obtaining a chi-square statistic as large as or larger than the observed value, given that the null hypothesis is true. If the p-value is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant association between the two variables, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant association between the variables, and the null hypothesis is accepted.\n",
    "\n",
    "The degrees of freedom for a chi-square test are equal to the number of rows in the contingency table minus 1 multiplied by the number of columns in the table minus 1. The degrees of freedom are used to determine the critical value of the chi-square statistic, which is used to determine the p-value.\n",
    "\n",
    "The expected frequencies are the frequencies that would be expected in each cell of the contingency table if the null hypothesis were true. They are calculated by taking the product of the row and column totals and dividing by the sample size. The expected frequencies are used to calculate the chi-square statistic and determine the statistical significance of the association between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6e64a",
   "metadata": {},
   "source": [
    "## Fisher's Extract Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a524f",
   "metadata": {},
   "source": [
    "The hypothesis test for a Fisher's exact test is used to determine if there is a significant association between two categorical variables. The null hypothesis is that there is no association between the two variables, and the alternative hypothesis is that there is an association between the variables.\n",
    "\n",
    "To perform the test, a contingency table is created to summarize the counts of each combination of the two variables. The Fisher's exact test is then applied to the contingency table to determine the statistical significance of the association between the variables.\n",
    "\n",
    "If the p-value obtained from the Fisher's exact test is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant association between the two variables, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant association between the variables, and the null hypothesis is accepted.\n",
    "\n",
    "It's important to note that the Fisher's exact test is used when the sample size is small or when the expected frequencies in the contingency table are small. It is not as powerful as the chi-square test for larger samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6961a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import fisher_exact\n",
    "\n",
    "# # Create contingency table\n",
    "# table = pd.crosstab(df['Product'], df['Price'])\n",
    "\n",
    "# odds_ratio, p_value = fisher_exact(table)\n",
    "\n",
    "# print(\"Odds ratio: \", odds_ratio)\n",
    "# print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7b331",
   "metadata": {},
   "source": [
    "The sample size for a Fisher's exact test is considered small when the expected frequencies in the contingency table are less than 5. When the expected frequencies are less than 5, the chi-square test may not be reliable due to the underlying assumptions of the test. In such cases, the Fisher's exact test is a more appropriate alternative.\n",
    "\n",
    "It's important to note that the Fisher's exact test is generally less powerful than the chi-square test, which means that it may be less able to detect significant differences between the observed and expected frequencies in the contingency table. As a result, it is generally recommended to use the chi-square test when the sample size is larger and the expected frequencies are greater than 5.\n",
    "\n",
    "It's also worth noting that the sample size for a statistical test is not the only factor that should be considered when deciding which test to use. Other factors, such as the nature of the data and the research question being addressed, should also be taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72207d49",
   "metadata": {},
   "source": [
    "## F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6dd6a",
   "metadata": {},
   "source": [
    "The hypothesis test for an F-test is used to determine if there is a significant difference between the means of two or more groups. The null hypothesis is that there is no difference between the means of the groups, and the alternative hypothesis is that there is a difference between the means of the groups.\n",
    "\n",
    "To perform the test, the F-statistic is calculated as the ratio of the mean square between groups (MSB) to the mean square within groups (MSW). The p-value is then calculated using the F-distribution, which is the distribution of the F-statistic under the null hypothesis.\n",
    "\n",
    "If the p-value obtained from the F-test is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant difference between the means of the groups, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant difference between the means of the groups, and the null hypothesis is accepted.\n",
    "\n",
    "It's important to note that the F-test is used to compare the means of two or more groups. It is not appropriate for comparing the means of two pairs of samples. To compare the means of two pairs of samples, you can use a t-test or a paired t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform F-test\n",
    "statistic, p_value = f_oneway(ireland_beef, france_beef)\n",
    "\n",
    "print(\"F-statistic: \", statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee81dc",
   "metadata": {},
   "source": [
    "The F-statistic is a measure of the ratio of the variance between the groups to the variance within the groups. It is calculated as the ratio of the mean square between groups (MSB) to the mean square within groups (MSW). The larger the F-statistic, the stronger the evidence against the null hypothesis (i.e., the more evidence there is for a significant difference between the means of the groups).\n",
    "\n",
    "The p-value is used to determine the statistical significance of the difference between the means of the groups. It is the probability of obtaining an F-statistic as large as or larger than the observed value, given that the null hypothesis is true. If the p-value is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant difference between the means of the groups, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant difference between the means of the groups, and the null hypothesis is accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d997e4e",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a8b9b",
   "metadata": {},
   "source": [
    "Assumptions\n",
    "1. Independence\n",
    "2. Normally disributed\n",
    "3. Quality of Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51406b40",
   "metadata": {},
   "source": [
    "#### H0 = means are equal\n",
    "#### H1 = at least one is not equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d33e58",
   "metadata": {},
   "source": [
    "One-way ANOVA and two-way ANOVA are both statistical tests used to compare the means of groups. The main difference between the two tests is the number of independent variables being considered.\n",
    "\n",
    "One-way ANOVA is used to compare the means of three or more groups, where there is only one independent variable. For example, if you want to compare the mean heights of three different species of plants, species would be the independent variable, and height would be the dependent variable. One-way ANOVA is used to determine if there is a significant difference in the mean heights of the plants due to the effect of the species.\n",
    "\n",
    "Two-way ANOVA is used to compare the means of groups, where there are two independent variables. For example, if you want to compare the mean heights of plants grown in two different soil types and exposed to two different levels of sunlight, soil type and sunlight exposure would be the independent variables, and height would be the dependent variable. Two-way ANOVA is used to determine if there is a significant difference in the mean heights of the plants due to the combined effects of the soil type and sunlight exposure.\n",
    "\n",
    "Both one-way ANOVA and two-way ANOVA involve testing the null hypothesis that there is no difference between the means of the groups. If the p-value obtained from the test is less than the chosen significance level (typically 0.05), it can be concluded that there is a significant difference between the means of the groups, and the null hypothesis can be rejected. On the other hand, if the p-value is greater than the significance level, it can be concluded that there is not a significant difference between the means of the groups, and the null hypothesis is accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f51d21",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb21ce",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23489ff",
   "metadata": {},
   "source": [
    "models to use on continuous data\n",
    "There are several machine learning models that are well suited for working with continuous data. Some common options include:\n",
    "\n",
    "Linear regression: Linear regression is a simple and widely used model that is used to predict a continuous target variable based on one or more continuous or categorical features. It is well suited for working with continuous data and can be used for both regression and classification tasks.\n",
    "\n",
    "Ridge regression: Ridge regression is a variant of linear regression that introduces a regularization term to the model to prevent overfitting. It is well suited for working with continuous data and can be used for both regression and classification tasks.\n",
    "\n",
    "Lasso regression: Lasso regression is another variant of linear regression that introduces a regularization term to the model to prevent overfitting. It is well suited for working with continuous data and can be used for both regression and classification tasks.\n",
    "\n",
    "Support vector machines (SVMs): SVMs are a type of linear model that is commonly used for classification tasks. They are well suited for working with continuous data, as they can handle both continuous and categorical features and can be used for both classification and regression tasks.\n",
    "\n",
    "Decision trees: Decision trees are a type of tree-based model that can be used for both classification and regression tasks. They are well suited for working with continuous data, as they can handle both continuous and categorical features.\n",
    "\n",
    "Random forests: Random forests are an ensemble learning method that combines multiple decision trees to make predictions. Like decision trees, they are well suited for working with continuous data and can be used for both classification and regression tasks.\n",
    "\n",
    "Ultimately, the choice of model will depend on the specific problem you are trying to solve and the characteristics of your dataset. It is a good idea to try a few different models and evaluate their performance on your dataset to determine which model is the best fit for your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a209ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Member State', 'Category'])\n",
    "\n",
    "# Create the independent and dependent variables\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ab89d",
   "metadata": {},
   "source": [
    "The R2 score, also known as the coefficient of determination, is a measure of how well the model fits the data. It is defined as the proportion of the variance in the target variable that is explained by the model. An R2 score of 1.0 indicates that the model perfectly fits the data, while an R2 score of 0.0 indicates that the model does not explain any of the variance in the target variable.\n",
    "\n",
    "The mean absolute error (MAE) is a measure of the average magnitude of the errors in the model's predictions. It is calculated as the average absolute difference between the predicted values and the true values. A smaller MAE score indicates that the model's predictions are closer to the true values on average.\n",
    "\n",
    "The mean squared error (MSE) is a measure of the average squared difference between the predicted values and the true values. It is generally preferred over the MAE because it penalizes larger errors more heavily. A smaller MSE score indicates that the model's predictions are closer to the true values on average.\n",
    "\n",
    "The root mean squared error (RMSE) is the square root of the MSE, and is expressed in the same units as the target variable. It is a more interpretable measure of error, as it is expressed in the same units as the target variable. Like the MSE, a smaller RMSE score indicates that the model's predictions are closer to the true values on average.\n",
    "\n",
    "Based on the scores you provided, it looks like the model is performing very well, with an R2 score of 1.0 and very small MAE, MSE, and RMSE scores. This suggests that the model is able to accurately fit the data and make very accurate predictions. It is worth noting, however, that these scores should be interpreted in the context of the problem you are trying to solve and the characteristics of your dataset. A model with excellent performance on one dataset may not necessarily perform as well on a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_data(X_train, y_train, X_test, y_test):\n",
    "#     \"\"\"Models data with decision tree, random forest, linear regression,\n",
    "#     ridge, lasso, and gradient boosting.\n",
    "    \n",
    "#     Parameters:\n",
    "#         X_train (ndarray): Training data features.\n",
    "#         y_train (ndarray): Training data labels.\n",
    "#         X_test (ndarray): Test data features.\n",
    "#         y_test (ndarray): Test data labels.\n",
    "    \n",
    "#     Returns:\n",
    "#         dict: Dictionary with the evaluation scores of the different models.\n",
    "#          \"\"\"\n",
    "#     # Create a dictionary to store the results\n",
    "#     results = {}\n",
    "    \n",
    "#     # Decision Tree\n",
    "#     # Define the hyperparameter space for decision tree\n",
    "#     dt_param_grid = {'max_depth': [3, 5, 7, 9, None],\n",
    "#                      'min_samples_split': [2, 4, 6, 8, 10],\n",
    "#                      'min_samples_leaf': [1, 3, 5, 7, 9]}\n",
    "    \n",
    "#     # Create a grid search object for decision tree\n",
    "#     dt_grid_search = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=dt_param_grid, cv=5)\n",
    "    \n",
    "#     # Fit the grid search object to the training data\n",
    "#     dt_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     dt_regressor = DecisionTreeRegressor(**dt_grid_search.best_params_)\n",
    "#     dt_regressor.fit(X, y)\n",
    "\n",
    "#     # Calculate the predicted value by calling a method predict()\n",
    "#     y_pred = dt_regressor.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = dt_regressor.score(X_train, y_train)\n",
    "#     test_score = dt_regressor.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Decision Tree'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     # Random Forest\n",
    "#     # Define the hyperparameter space for random forest\n",
    "#     rf_param_grid = {'n_estimators': [10, 50, 100, 200, 300],\n",
    "#                      'max_depth': [3, 5, 7, 9, None],\n",
    "#                      'min_samples_split': [2, 4, 6, 8, 10],\n",
    "#                      'min_samples_leaf': [1, 3, 5, 7, 9]}\n",
    "    \n",
    "#     # Create a grid search object for random forest\n",
    "#     rf_grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=rf_param_grid, cv=5)\n",
    "    \n",
    "#     # Fit the grid search object to the training data\n",
    "#     rf_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     rf_regressor = RandomForestRegressor(**rf_grid_search.best_params_)\n",
    "#     rf_regressor.fit(X, y)\n",
    "\n",
    "#     # Calculate the predicted value by calling a method predict()\n",
    "#     y_pred = rf_regressor.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = rf_regressor.score(X_train, y_train)\n",
    "#     test_score = rf_regressor.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Random Forest'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     # Linear Regression\n",
    "#     # Model data with linear regression\n",
    "#     lr_model = LinearRegression()\n",
    "    \n",
    "#     # Define the hyperparameter space for linear regression\n",
    "#     lr_param_grid = {'normalize': [True, False],\n",
    "#                      'fit_intercept': [True, False]}\n",
    "    \n",
    "#     # Create a grid search object for linear regression\n",
    "#     lr_grid_search = GridSearchCV(estimator=lr_model, param_grid=lr_param_grid, cv=10)\n",
    "   \n",
    "#     # Train the model and search for the best hyperparameters\n",
    "#     lr_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     linear_model = LinearRegression(**lr_grid_search.best_params_)\n",
    "#     linear_model.fit(X, y)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = linear_model.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = linear_model.score(X_train, y_train)\n",
    "#     test_score = linear_model.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Linear Regression'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     # Ridge Regression\n",
    "#     # Define the hyperparameter space for ridge regression\n",
    "#     ridge_param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "#                         'normalize': [True, False],\n",
    "#                         'fit_intercept': [True, False]}\n",
    "    \n",
    "#     # Create a grid search object for ridge regression\n",
    "#     ridge_grid_search = GridSearchCV(estimator=Ridge(), param_grid=ridge_param_grid, cv=5)\n",
    "    \n",
    "#     # Fit the grid search object to the training data\n",
    "#     ridge_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     ridge_regressor = Ridge(**ridge_grid_search.best_params_)\n",
    "#     ridge_regressor.fit(X, y)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = ridge_regressor.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = ridge_regressor.score(X_train, y_train)\n",
    "#     test_score = ridge_regressor.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Ridge Regression'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     # Lasso Regression\n",
    "#     # Define the hyperparameter space for lasso regression\n",
    "#     lasso_param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "#                         'normalize': [True, False],\n",
    "#                         'fit_intercept': [True, False]}\n",
    "    \n",
    "#     # Create a grid search object for lasso regression\n",
    "#     lasso_grid_search = GridSearchCV(estimator=Lasso(), param_grid=lasso_param_grid, cv=10)\n",
    "\n",
    "#     # Fit the grid search object to the training data\n",
    "#     lasso_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     lasso_regressor = Lasso(**lasso_grid_search.best_params_)\n",
    "#     lasso_regressor.fit(X, y)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     y_pred = lasso_regressor.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = lasso_regressor.score(X_train, y_train)\n",
    "#     test_score = lasso_regressor.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Lasso Regression'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     # Gradient Boosting\n",
    "#     # Define the hyperparameter space for gradient boosting\n",
    "#     gb_param_grid = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "#                      'learning_rate': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "#                      'n_estimators': [10, 50, 100, 200, 300],\n",
    "#                      'max_depth': [3, 5, 7, 9, None],\n",
    "#                      'min_samples_split': [2, 4, 6, 8, 10],\n",
    "#                      'min_samples_leaf': [1, 3, 5, 7, 9]}\n",
    "#     # Create a grid search object for gradient boosting\n",
    "#     gb_grid_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=gb_param_grid, cv=5)\n",
    "    \n",
    "#     # Fit the grid search object to the training data\n",
    "#     gb_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the model on the entire dataset using the best parameters\n",
    "#     gb_regressor = GradientBoostingRegressor(**gb_grid_search.best_params_)\n",
    "#     gb_regressor.fit(X, y)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = gb_regressor.predict(X_test)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     train_score = gb_regressor.score(X_train, y_train)\n",
    "#     test_score = gb_regressor.score(X_test, y_test)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     results['Gradient Boosting'] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'Train Score': train_score, \n",
    "#                                 'Test Score': test_score, 'R2': r2}\n",
    "    \n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30453491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes 6 hours to run\n",
    "# # Notify me when this cell is finished running\n",
    "# %%notify\n",
    "\n",
    "# # Call the model_data() function and pass it the training and test data\n",
    "# results = model_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# # Initialize a table with the desired column names\n",
    "# table = PrettyTable(['Model', 'MAE', 'MSE', 'RMSE', 'Train Score', 'Test Score','R2'])\n",
    "\n",
    "# # Iterate over the results and add a row for each model\n",
    "# for model, scores in results.items():\n",
    "#     table.add_row([model, scores['MAE'], scores['MSE'], scores['RMSE'], scores['Train Score'], \n",
    "#                    scores['Test Score'], scores['R2']])\n",
    "\n",
    "# # Print the table\n",
    "# print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6fe1e",
   "metadata": {},
   "source": [
    "This output is a table showing the performance of various machine learning models on a given dataset. The models listed are Decision Tree, Random Forest, Linear Regression, Ridge Regression, Lasso Regression, and Gradient Boosting.\n",
    "\n",
    "The table shows the following performance metrics for each model:\n",
    "\n",
    "MAE (Mean Absolute Error): This is the average absolute difference between the predicted values and the actual values. A lower MAE indicates a better fit.\n",
    "\n",
    "MSE (Mean Squared Error): This is the average squared difference between the predicted values and the actual values. A lower MSE indicates a better fit.\n",
    "\n",
    "RMSE (Root Mean Squared Error): This is the square root of the MSE. It is commonly used as a measure of the magnitude of the error. A lower RMSE indicates a better fit.\n",
    "\n",
    "Train Score: This is the score of the model on the training dataset. It is generally higher than the test score, as the model has been trained on the training data and should perform better on it.\n",
    "\n",
    "Test Score: This is the score of the model on the test dataset. It is a measure of how well the model generalizes to new, unseen data.\n",
    "\n",
    "R2: This is the coefficient of determination, which is a measure of how well the model explains the variance in the data. An R2 of 1 indicates that the model perfectly fits the data.\n",
    "\n",
    "In this table, all of the models have very low MAE, MSE, and RMSE values, as well as high train and test scores and R2 values. This suggests that all of the models are performing very well on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141ea37",
   "metadata": {},
   "source": [
    "In general, a model with a low MAE, MSE, and RMSE and a high R2 score is considered to be performing well. However, you should also consider other factors such as the complexity of the model, the time it takes to train and make predictions, and its ability to generalize to new data.\n",
    "\n",
    "In this case, it looks like the Decision Tree and Random Forest models have the lowest error metrics, but their R2 scores are not as high as the other models. The Linear Regression, Ridge Regression, and Lasso models have lower error metrics and higher R2 scores, but they may be more complex and take longer to train. The Gradient Boosting model has intermediate values for the error metrics and the R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install notify-run\n",
    "\n",
    "# import notify_run\n",
    "# notify_run.register()\n",
    "\n",
    "# # Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the figure\n",
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "# Display the tree by calling a method plot_tree()\n",
    "tree.plot_tree(dt_regressor.fit(X_train, y_train),filled=True, rounded=True, precision=2) ;\n",
    "\n",
    "# Save the image else where to be used in report\n",
    "plt.savefig('./Images/Img4_pearson_corr_heatmap.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91534629",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if y.ndim == 1:\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "# Remove the target variable\n",
    "X = df.drop(columns=['Cattle Price'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the hyperparameter space for the unsupervised learning algorithm\n",
    "param_grid = {'n_components': [2, 3, 4],\n",
    "              'n_clusters': [2, 3, 4]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    clusters = estimator.predict(X)\n",
    "    return metrics.silhouette_score(X, clusters)\n",
    "\n",
    "# Create a grid search object\n",
    "clustering_grid_search = GridSearchCV(estimator=KMeans(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "clustering_grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_clustering = KMeans(**clustering_grid_search.best_params_)\n",
    "best_clustering.fit(X_scaled)\n",
    "\n",
    "# Calculate the predicted value by calling a method predict()\n",
    "y_pred = best_clustering.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17839b5",
   "metadata": {},
   "source": [
    "This code uses k-means for clustering and grid search CV to find the optimal number of clusters. The code also defines a scoring function based on the silhouette score, which is a measure of how well each point is assigned to its own cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb026f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define the hyperparameter space for the unsupervised learning algorithm\n",
    "param_grid = {'n_components': [2, 3, 4],\n",
    "              'alpha': [0.1, 0.5, 1.0]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    return metrics.calinski_harabasz_score(X, estimator.transform(X))\n",
    "\n",
    "# Create a grid search object\n",
    "pca_grid_search = GridSearchCV(estimator=PCA(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "pca_grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_pca = PCA(**pca_grid_search.best_params_)\n",
    "best_pca.fit(X_scaled)\n",
    "\n",
    "# Calculate the explained variance ratio\n",
    "explained_variance = best_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd408702",
   "metadata": {},
   "source": [
    "This code uses principal component analysis (PCA) for dimensionality reduction and grid search CV to find the optimal number of components. The code also defines a scoring function based on the Calinski-Harabasz score, which is a measure of the compactness of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked\n",
    "# Define the hyperparameter space for the clustering algorithm\n",
    "param_grid = {'n_clusters': [2, 3, 4, 5],\n",
    "              'tol': [1e-4, 1e-3, 1e-2]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    return metrics.calinski_harabasz_score(X, estimator.predict(X))\n",
    "\n",
    "# Create a grid search object\n",
    "kmeans_grid_search = GridSearchCV(estimator=KMeans(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "kmeans_grid_search.fit(X_scaled)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_kmeans = KMeans(**kmeans_grid_search.best_params_)\n",
    "best_kmeans.fit(X_scaled)\n",
    "\n",
    "# Calculate the cluster assignments\n",
    "cluster_assignments = best_kmeans.predict(X_scaled)\n",
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ad91e",
   "metadata": {},
   "source": [
    "This code uses the k-means clustering algorithm and grid search CV to find the optimal number of clusters. The code also defines a scoring function based on the Calinski-Harabasz score, which is a measure of the compactness and separation of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter space for the unsupervised learning algorithm\n",
    "param_grid = {'n_clusters': [2, 3, 4],\n",
    "              'max_iter': [100, 200, 300]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    return metrics.silhouette_score(X, estimator.predict(X))\n",
    "\n",
    "# Create a grid search object\n",
    "kmeans_grid_search = GridSearchCV(estimator=KMeans(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "kmeans_grid_search.fit(X_scaled)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_kmeans = KMeans(**kmeans_grid_search.best_params_)\n",
    "best_kmeans.fit(X_scaled)\n",
    "\n",
    "# Calculate the cluster assignments\n",
    "cluster_assignments = best_kmeans.predict(X_scaled)\n",
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438dad38",
   "metadata": {},
   "source": [
    "This code uses k-means clustering for data partitioning and grid search CV to find the optimal number of clusters. The code also defines a scoring function based on the silhouette score, which is a measure of the compactness and separation of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7769ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define the hyperparameter space for the unsupervised learning algorithm\n",
    "param_grid = {'n_components': [2, 3, 4, 5],\n",
    "              'tol': [1e-4, 1e-3, 1e-2]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    return metrics.silhouette_score(X, estimator.transform(X))\n",
    "\n",
    "# Create a grid search object\n",
    "pca_grid_search = GridSearchCV(estimator=PCA(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "pca_grid_search.fit(X_scaled)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_pca = PCA(**pca_grid_search.best_params_)\n",
    "best_pca.fit(X_scaled)\n",
    "\n",
    "# Calculate the principal components\n",
    "principal_components = best_pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10047b6",
   "metadata": {},
   "source": [
    "This code uses principal component analysis (PCA) for dimensionality reduction and grid search CV to find the optimal number of components. The code also defines a scoring function based on the silhouette score, which is a measure of the compactness and separation of the data points in the reduced-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Apply a dimensionality reduction algorithm\n",
    "tsne = TSNE(n_components=2)\n",
    "X_reduced = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Apply a clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X_reduced)\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcda4d7",
   "metadata": {},
   "source": [
    "This code is similar to the previous example, but it uses t-distributed stochastic neighbor embedding (t-SNE) for dimensionality reduction and DBSCAN for clustering. The code also visualizes the results by plotting the data points with colors indicating the cluster to which each point belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter space for t-SNE\n",
    "param_grid = {'perplexity': [5, 10, 20, 30, 50],\n",
    "              'learning_rate': [10, 50, 100, 200]}\n",
    "\n",
    "# Create a grid search object for t-SNE\n",
    "tsne_grid_search = GridSearchCV(estimator=TSNE(), param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "tsne_grid_search.fit(X_scaled)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_tsne = TSNE(**tsne_grid_search.best_params_)\n",
    "X_tsne = best_tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Define the hyperparameter space for DBSCAN\n",
    "param_grid = {'eps': [0.5, 1, 1.5, 2],\n",
    "              'min_samples': [5, 10, 15, 20]}\n",
    "\n",
    "# Create a grid search object for DBSCAN\n",
    "dbscan_grid_search = GridSearchCV(estimator=DBSCAN(), param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the t-SNE transformed data\n",
    "dbscan_grid_search.fit(X_tsne)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_dbscan = DBSCAN(**dbscan_grid_search.best_params_)\n",
    "best_dbscan.fit(X_tsne)\n",
    "\n",
    "# Calculate the predicted clusters\n",
    "clusters = best_dbscan.labels_\n",
    "\n",
    "# Print the results\n",
    "#print(\"Optimal\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters)\n",
    "plt.show()\n",
    "\n",
    "# Check the performance of the model using metrics such as homogeneity, completeness, and V-measure\n",
    "print(metrics.homogeneity_score(df['target'], clusters))\n",
    "print(metrics.completeness_score(df['target'], clusters))\n",
    "print(metrics.v_measure_score(df['target'], clusters))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386cab4",
   "metadata": {},
   "source": [
    "This code uses the t-SNE and DBSCAN algorithms, along with grid search CV, to find the optimal parameters for dimensionality reduction and clustering, respectively. The code first standardizes the data, then applies t-SNE to reduce the dimensionality of the data to two dimensions. The resulting t-SNE transformed data is then used as input to the DBSCAN algorithm, which clusters the data into different groups based on the specified parameters.\n",
    "\n",
    "This code first visualizes the results of the clustering by plotting the t-SNE transformed data points with colors representing the predicted clusters. It then calculates and prints some evaluation metrics for the clustering model, such as homogeneity, completeness, and V-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50603e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "# Define the hyperparameter space for the anomaly detection algorithm\n",
    "param_grid = {'contamination': [0.1, 0.2, 0.3],\n",
    "              'support_fraction': [0.5, 0.6, 0.7]}\n",
    "\n",
    "# Define a scoring function\n",
    "def scoring_function(estimator, X, y):\n",
    "    return metrics.roc_auc_score(y, estimator.decision_function(X))\n",
    "\n",
    "# Create a grid search object\n",
    "isolation_forest_grid_search = GridSearchCV(estimator=IsolationForest(), param_grid=param_grid, cv=5, scoring=scoring_function)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "isolation_forest_grid_search.fit(X_scaled)\n",
    "\n",
    "# Train the model on the entire dataset using the best parameters\n",
    "best_isolation_forest = IsolationForest(**isolation_forest_grid_search.best_params_)\n",
    "best_isolation_forest.fit(X_scaled)\n",
    "\n",
    "# Calculate the predicted scores\n",
    "scores = best_isolation_forest.decision_function(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b942847",
   "metadata": {},
   "source": [
    "This code uses the Isolation Forest algorithm and grid search CV to find the optimal contamination level and support fraction parameters for anomaly detection. The code also defines a scoring function based on the area under the ROC curve (AUC), which is a measure of the model's ability to distinguish between normal and anomalous samples.\n",
    "\n",
    "You can modify this code to use different anomaly detection algorithms and scoring functions as needed, depending on the nature of the data and the specific patterns or structures that you are trying to capture or identify. Some common anomaly detection algorithms include Isolation Forest, Local Outlier Factor, and One-Class SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76a60d",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "# Create a row to hold the plot column and a table showing the daily returns\n",
    "dashboard = pn.Row(plot_column, pn.panel(daily_returns, title=\"Daily Returns\"))\n",
    "\n",
    "# Add the slider and plots/table to the dashboard\n",
    "dashboard = pn.Column(window_size_slider, dashboard, update_plots)\n",
    "\n",
    "dashboard.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc124f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
